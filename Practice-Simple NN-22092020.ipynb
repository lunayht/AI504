{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 23 11:14:35 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.66       Driver Version: 450.66       CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 105...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   43C    P3    N/A /  N/A |    234MiB /  2002MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       986      G   /usr/lib/xorg/Xorg                 45MiB |\n",
      "|    0   N/A  N/A      1500      G   /usr/lib/xorg/Xorg                106MiB |\n",
      "|    0   N/A  N/A      1679      G   /usr/bin/gnome-shell               71MiB |\n",
      "|    0   N/A  N/A      2287      G   /usr/lib/firefox/firefox            1MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n",
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# set device to gpu if it's available \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ```torch.rand(10).to(device)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1507, 0.2810, 0.4432, 0.0280, 0.6526, 0.2904, 0.2309, 0.3560, 0.9437,\n",
      "        0.6874], device='cuda:0')\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a simple NN with two hidden layers using Pytorch\n",
    "\n",
    "### Load MNIST datasets from pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset:\n",
      "60000\n",
      "\n",
      "Training dataset, m:\n",
      "50000\n",
      "\n",
      "Validation dataset:\n",
      "10000\n",
      "\n",
      "Test dataset:\n",
      "10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# MNIST dataset \n",
    "total_datasets = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Split into validation and test\n",
    "train_dataset, val_dataset = random_split(total_datasets, [50000, 10000])\n",
    "\n",
    "print(f\"Total dataset:\\n{len(total_datasets)}\\n\")\n",
    "print(f\"Training dataset, m:\\n{len(train_dataset)}\\n\")\n",
    "print(f\"Validation dataset:\\n{len(val_dataset)}\\n\")\n",
    "print(f\"Test dataset:\\n{len(test_dataset)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 1, 28, 28])\n",
      "number of features, n:\n",
      "784\n",
      "\n",
      "hidden size;\n",
      "60\n",
      "\n",
      "output size:\n",
      "10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=250, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1000, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)\n",
    "\n",
    "n = images.shape[2] * images.shape[3]\n",
    "output_size = len(total_datasets.classes)\n",
    "hidden_size = 60\n",
    "\n",
    "print(f\"number of features, n:\\n{n}\\n\")\n",
    "print(f\"hidden size;\\n{hidden_size}\\n\")\n",
    "print(f\"output size:\\n{output_size}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression of 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.L1 = nn.Linear(input_size, hidden_size)\n",
    "        self.L2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.L3 = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, A0):\n",
    "        Z1 = self.L1(A0)\n",
    "        A1 = self.tanh(Z1)\n",
    "        Z2 = self.L2(A1)\n",
    "        A2 = self.tanh(Z2)\n",
    "        Z3 = self.L2(A2)\n",
    "        A3 = self.tanh(Z3)\n",
    "        Y_hat = self.L3(A3)\n",
    "        return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create model\n",
    "model = Model(n, hidden_size, output_size)\n",
    "\n",
    "# upload model to gpu\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iterations:\n",
      "200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.075, momentum=0.9)\n",
    "\n",
    "total_iterations = len(train_loader)\n",
    "print(f\"total iterations:\\n{total_iterations}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]; Step[100/200]; Loss: 0.4104525148868561\n",
      "Epoch [1]; Step[200/200]; Loss: 0.14551442861557007\n",
      "Cross Validation Error: 6.86\n",
      "Epoch [2]; Step[100/200]; Loss: 0.18161030113697052\n",
      "Epoch [2]; Step[200/200]; Loss: 0.10409998893737793\n",
      "Cross Validation Error: 4.75\n",
      "Epoch [3]; Step[100/200]; Loss: 0.11801781505346298\n",
      "Epoch [3]; Step[200/200]; Loss: 0.12576176226139069\n",
      "Cross Validation Error: 4.1\n",
      "Epoch [4]; Step[100/200]; Loss: 0.08139833807945251\n",
      "Epoch [4]; Step[200/200]; Loss: 0.05503647029399872\n",
      "Cross Validation Error: 3.45\n",
      "Epoch [5]; Step[100/200]; Loss: 0.06068909168243408\n",
      "Epoch [5]; Step[200/200]; Loss: 0.09272748976945877\n",
      "Cross Validation Error: 3.42\n",
      "Epoch [6]; Step[100/200]; Loss: 0.05771825462579727\n",
      "Epoch [6]; Step[200/200]; Loss: 0.04894643649458885\n",
      "Cross Validation Error: 3.13\n",
      "Epoch [7]; Step[100/200]; Loss: 0.03518432751297951\n",
      "Epoch [7]; Step[200/200]; Loss: 0.06492739170789719\n",
      "Cross Validation Error: 2.92\n",
      "Epoch [8]; Step[100/200]; Loss: 0.02612335793673992\n",
      "Epoch [8]; Step[200/200]; Loss: 0.14138977229595184\n",
      "Cross Validation Error: 3.34\n",
      "Epoch [9]; Step[100/200]; Loss: 0.09608451277017593\n",
      "Epoch [9]; Step[200/200]; Loss: 0.0659445971250534\n",
      "Cross Validation Error: 3.21\n",
      "Epoch [10]; Step[100/200]; Loss: 0.022678084671497345\n",
      "Epoch [10]; Step[200/200]; Loss: 0.025817295536398888\n",
      "Cross Validation Error: 2.91\n",
      "Epoch [11]; Step[100/200]; Loss: 0.01394286286085844\n",
      "Epoch [11]; Step[200/200]; Loss: 0.02017664723098278\n",
      "Cross Validation Error: 2.85\n",
      "Epoch [12]; Step[100/200]; Loss: 0.03292415291070938\n",
      "Epoch [12]; Step[200/200]; Loss: 0.06139107421040535\n",
      "Cross Validation Error: 2.99\n",
      "Epoch [13]; Step[100/200]; Loss: 0.031172703951597214\n",
      "Epoch [13]; Step[200/200]; Loss: 0.01805541105568409\n",
      "Cross Validation Error: 3.09\n",
      "Epoch [14]; Step[100/200]; Loss: 0.011687724851071835\n",
      "Epoch [14]; Step[200/200]; Loss: 0.008691491559147835\n",
      "Cross Validation Error: 2.98\n",
      "Epoch [15]; Step[100/200]; Loss: 0.009750685654580593\n",
      "Epoch [15]; Step[200/200]; Loss: 0.018108408898115158\n",
      "Cross Validation Error: 2.75\n",
      "Epoch [16]; Step[100/200]; Loss: 0.006012070458382368\n",
      "Epoch [16]; Step[200/200]; Loss: 0.017630910500884056\n",
      "Cross Validation Error: 3.01\n",
      "Epoch [17]; Step[100/200]; Loss: 0.005761442240327597\n",
      "Epoch [17]; Step[200/200]; Loss: 0.020928440615534782\n",
      "Cross Validation Error: 3.01\n",
      "Epoch [18]; Step[100/200]; Loss: 0.032214801758527756\n",
      "Epoch [18]; Step[200/200]; Loss: 0.009722488932311535\n",
      "Cross Validation Error: 2.83\n",
      "Epoch [19]; Step[100/200]; Loss: 0.014079946093261242\n",
      "Epoch [19]; Step[200/200]; Loss: 0.048622969537973404\n",
      "Cross Validation Error: 2.66\n",
      "Epoch [20]; Step[100/200]; Loss: 0.0041245631873607635\n",
      "Epoch [20]; Step[200/200]; Loss: 0.008989078924059868\n",
      "Cross Validation Error: 2.72\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward propagation\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss for every 100 steps\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}]; Step[{i+1}/{total_iterations}]; Loss: {loss.item()}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        wrong = 0\n",
    "        total = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            wrong += (predicted != labels).sum().item()\n",
    "            \n",
    "    print(f\"Cross Validation Error: {100*wrong/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 97.3%\n"
     ]
    }
   ],
   "source": [
    "# Check test accuracy\n",
    "with torch.no_grad():\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of model: {100*test_correct/test_total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network with 2 layers\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create model\n",
    "model = ConvNet()\n",
    "\n",
    "# upload model to gpu\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iterations:\n",
      "200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.075, momentum=0.9)\n",
    "\n",
    "total_iterations = len(train_loader)\n",
    "print(f\"total iterations:\\n{total_iterations}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]; Step[100/200]; Loss: 0.8110878467559814\n",
      "Epoch [1]; Step[200/200]; Loss: 0.3705999255180359\n",
      "Cross Validation Error: 11.48\n",
      "Epoch [2]; Step[100/200]; Loss: 0.25753629207611084\n",
      "Epoch [2]; Step[200/200]; Loss: 0.22113129496574402\n",
      "Cross Validation Error: 6.31\n",
      "Epoch [3]; Step[100/200]; Loss: 0.2028256058692932\n",
      "Epoch [3]; Step[200/200]; Loss: 0.17020109295845032\n",
      "Cross Validation Error: 5.04\n",
      "Epoch [4]; Step[100/200]; Loss: 0.09933213144540787\n",
      "Epoch [4]; Step[200/200]; Loss: 0.12741895020008087\n",
      "Cross Validation Error: 4.04\n",
      "Epoch [5]; Step[100/200]; Loss: 0.11212226748466492\n",
      "Epoch [5]; Step[200/200]; Loss: 0.12445715069770813\n",
      "Cross Validation Error: 3.48\n",
      "Epoch [6]; Step[100/200]; Loss: 0.12142695486545563\n",
      "Epoch [6]; Step[200/200]; Loss: 0.07061251252889633\n",
      "Cross Validation Error: 3.2\n",
      "Epoch [7]; Step[100/200]; Loss: 0.09561962634325027\n",
      "Epoch [7]; Step[200/200]; Loss: 0.08732737600803375\n",
      "Cross Validation Error: 3.1\n",
      "Epoch [8]; Step[100/200]; Loss: 0.11328326910734177\n",
      "Epoch [8]; Step[200/200]; Loss: 0.060130972415208817\n",
      "Cross Validation Error: 2.96\n",
      "Epoch [9]; Step[100/200]; Loss: 0.06882026791572571\n",
      "Epoch [9]; Step[200/200]; Loss: 0.1064060628414154\n",
      "Cross Validation Error: 2.62\n",
      "Epoch [10]; Step[100/200]; Loss: 0.0832194834947586\n",
      "Epoch [10]; Step[200/200]; Loss: 0.10459692776203156\n",
      "Cross Validation Error: 2.66\n",
      "Epoch [11]; Step[100/200]; Loss: 0.05605127289891243\n",
      "Epoch [11]; Step[200/200]; Loss: 0.12132520228624344\n",
      "Cross Validation Error: 2.86\n",
      "Epoch [12]; Step[100/200]; Loss: 0.12363787740468979\n",
      "Epoch [12]; Step[200/200]; Loss: 0.0568515807390213\n",
      "Cross Validation Error: 2.59\n",
      "Epoch [13]; Step[100/200]; Loss: 0.05686821788549423\n",
      "Epoch [13]; Step[200/200]; Loss: 0.04507395252585411\n",
      "Cross Validation Error: 2.38\n",
      "Epoch [14]; Step[100/200]; Loss: 0.055237751454114914\n",
      "Epoch [14]; Step[200/200]; Loss: 0.059933338314294815\n",
      "Cross Validation Error: 2.47\n",
      "Epoch [15]; Step[100/200]; Loss: 0.05922122299671173\n",
      "Epoch [15]; Step[200/200]; Loss: 0.06518635898828506\n",
      "Cross Validation Error: 2.34\n",
      "Epoch [16]; Step[100/200]; Loss: 0.012827725149691105\n",
      "Epoch [16]; Step[200/200]; Loss: 0.05126916989684105\n",
      "Cross Validation Error: 2.27\n",
      "Epoch [17]; Step[100/200]; Loss: 0.07279668748378754\n",
      "Epoch [17]; Step[200/200]; Loss: 0.043065145611763\n",
      "Cross Validation Error: 2.25\n",
      "Epoch [18]; Step[100/200]; Loss: 0.04915972054004669\n",
      "Epoch [18]; Step[200/200]; Loss: 0.045204199850559235\n",
      "Cross Validation Error: 2.3\n",
      "Epoch [19]; Step[100/200]; Loss: 0.04978666454553604\n",
      "Epoch [19]; Step[200/200]; Loss: 0.07061758637428284\n",
      "Cross Validation Error: 2.5\n",
      "Epoch [20]; Step[100/200]; Loss: 0.044793471693992615\n",
      "Epoch [20]; Step[200/200]; Loss: 0.04652244970202446\n",
      "Cross Validation Error: 2.12\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward propagation\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss for every 100 steps\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}]; Step[{i+1}/{total_iterations}]; Loss: {loss.item()}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        wrong = 0\n",
    "        total = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            wrong += (predicted != labels).sum().item()\n",
    "            \n",
    "    print(f\"Cross Validation Error: {100*wrong/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 98.01%\n"
     ]
    }
   ],
   "source": [
    "# Check test accuracy\n",
    "with torch.no_grad():\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of model: {100*test_correct/test_total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As we can see from the above examples, ConvNet performs better than multilayer perceptron (multiple layers of logistic regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
